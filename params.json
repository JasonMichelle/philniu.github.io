{
  "name": "3D Hand Tracking",
  "tagline": "image analysis&understanding project：3D Hand Tracking",
  "body": "# Members: \r\n牛群杰 罗攀 陈福坤 李国胜\r\n# Introduction\r\nIn the field of technology and image processing, hand/finger tracking is \r\na high-resolution technique that is employed to know the consecutive position \r\nof the hands/fingers of the user and hence represent objects in 3D. In addition \r\nto that, the hand/finger tracking technique is used as a tool of the computer, \r\nacting as an external device in our computer, similar to a keyboard and \r\na mouse.      \r\n# Time Line      \r\n1.Creat github homepage                 \r\n2.Android环境搭建                 \r\n# To Do List\r\n1.分配任务，创建项目链接                     \r\n2.Android环境搭建           \r\n3.阅读参考文献，寻找合适算法，确定待实现方案             \r\n\r\n# Reference\r\n[1]. Fast and Robust Hand Tracking Using Detection-Guided Optimization, In CVPR, 2015.     \r\n[2]. Accurate, Robust, and Flexible Real-time Hand Tracking, In CHI, 2015.      \r\n[3]. Full DOF tracking of a hand interaction with an object by modeling occlusions and physical constraints, In ICCV, 2011.     \r\n\r\n# Corresponding Video Links\r\nhttp://v.youku.com/v_show/id_XNzk2NDM4NDIw.html?from=s1.8-1-1.2     \r\nhttps://www.youtube.com/watch?v=FNQbGJyGAs8 (YouTube video)     \r\nhttps://www.youtube.com/watch?v=xML2S6bvMwI(YouTube video)     \r\nhttps://www.youtube.com/watch?v=eXktGa16yXk (YouTube video)     \r\nhttps://www.youtube.com/watch?v=N3ffgj1bBGw (YouTube video)    \r\n\r\n# UPDATE2：Android环境搭建\r\n随着移动互联网的火热发展和移动端迅速崛起，Android的应用开发和IOS应用开发是非常有必要了解学习的。\r\n本文就是为了从最基本的开始介绍Android开发。在整个文档中，我会简单介绍环境搭建、最小案例演示、JNI开发和集成OpenCV。      \r\n**工具**        \r\n⒈JDK    \r\n⒉Eclipse   \r\n⒊Android SDK   \r\n⒋Android NDK   \r\n⒌OpenCV-2.4.11的AndroidSDK      \r\n\r\n**1. JDK安装和Java环境配置**      \r\n下载地址：http://www.oracle.com/technetwork/java/javase/downloads/index.html\r\n环境配置，截图如下：   \r\nJAVA_HOME   \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/1.png)                \r\nPATH     \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/2.png)         \r\nCLASSPATH    \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/3.png)                                         \r\nWin+R，输入cmd，输入java 和 javac 检测环境是否配置成功。成功的话会出现很多输出      \r\n\r\n**2. Eclipse下载安装**     \r\n下载地址：http://www.eclipse.org/downloads/    \r\n选择适用于Android开发的IDE      \r\n然后像普通的windows软件一样的安装。图片就不截了。    \r\n\r\n**3. Android相关下载**                \r\n在这里，我不得不说一句。墙内的我们，学个开发就这么难吗？   \r\n还有国内有个不错的论坛，所有android需要的都可以去那里下载：   \r\n网址：http://www.apkbus.com/thread-252748-1-1.html    \r\n还有就是，作为新手。我建议，直接下载我给的网址里面的一个名叫ADT Bundle的文件，也就是说不需要去进行第二步。下载完成以后，解压就可以直接使用。不过，这个集成好的里面的Android版本不是最新的，并且如果想更新的话也是相当的麻烦。个人建议不要更新。凑合用，等理解深刻了，完整的走一趟安装流程。     \r\n\r\n**4. Android SDK和NDK配置**         \r\n打开Eclipse，设置工作空间。      \r\nWindow—>Preference看如下截图：     \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/4.png)                                    \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/5.png)                                         \r\n\r\n**5. 配置OpenCV-2.4.11**        \r\n下载地址：http://opencv.org/downloads.html    \r\n选择相应的版本。    \r\n解压文件，然后把文件里面的一个名叫sdk的文件夹复制到工作空间。        \r\n然后，导入这个sdk项目到Eclipse作为一个library。      \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/6.png)                            \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/7.png)                                                \r\n**6. 创建一个简单地使用OPenCV的本地代码实现图片灰度化的项目。**                                         \r\n![](https://github.com/philniu/philniu.github.io/blob/master/AndroidPictures/8.png)                                                                               \r\n\r\n**7. 备注**                    \r\n后续更新，敬请期待。                \r\n\r\n# UPDATE3:3D动态立体显示   \r\n\r\n打开Eclipse，创建一个项目，取名Dj3DStudy001，采用Android5.1，也就是Android API 22版本。向下兼容到Android API 14. \r\n完成的效果如下图：（本来是一个动画，但是手机运行之后，录制动画太麻烦，就弄一组图算了）   \r\n![](https://github.com/philniu/philniu.github.io/tree/master/update3Images/1.png)  \r\n\r\n**项目架构截图：**  \r\n![](https://github.com/philniu/philniu.github.io/tree/master/update3Images/2.png)  \r\n\r\n**代码**   \r\n\r\n1、完成3D立方体的绘制，代码注释  \r\n\r\n    package com.hust.dj3dstudy;\r\n\r\n    import java.nio.ByteBuffer;\r\n    import java.nio.ByteOrder\r\n    import java.nio.FloatBuffer;\r\n\r\n    import javax.microedition.khronos.egl.EGLConfig;\r\n    import javax.microedition.khronos.opengles.GL10;\r\n\r\n    import android.opengl.GLSurfaceView.Renderer;\r\n    import android.opengl.GLU;\r\n\r\n    public class CubeRenderer implements Renderer {\r\n\r\n\t//调整这个小说就可以调整这个立方体的大小。\r\n\tfloat box[] = new float[] {\r\n\t\t\t// FRONT\r\n\t\t\t-0.25f, -0.25f, 0.25f,\r\n\t\t\t 0.25f, -0.25f, 0.25f,\r\n\t\t\t-0.25f,  0.25f, 0.25f,\r\n\t\t\t 0.25f,  0.25f, 0.25f,\r\n\t\t\t// BACK\r\n\t\t\t-0.25f, -0.25f, -0.25f, \r\n\t\t\t-0.25f,  0.25f, -0.25f, \r\n\t\t\t 0.25f, -0.25f, -0.25f,\r\n\t\t  \t 0.25f,  0.25f, -0.25f,\r\n\t\t\t// LEFT\r\n\t\t\t-0.25f, -0.25f,  0.25f, \r\n\t\t\t-0.25f,  0.25f,  0.25f, \r\n\t\t\t-0.25f, -0.25f, -0.25f,\r\n\t\t\t-0.25f,  0.25f, -0.25f,\r\n\t\t\t// RIGHT\r\n\t\t\t0.25f, -0.25f, -0.25f, \r\n\t\t\t0.25f, 0.25f, -0.25f, \r\n\t\t\t0.25f, -0.25f, 0.25f, \r\n\t\t\t0.25f,0.25f,0.25f,\r\n\t\t\t// TOP\r\n\t\t\t-0.25f, 0.25f, 0.25f, \r\n\t\t\t0.25f, 0.25f, 0.25f, \r\n\t\t\t-0.25f, 0.25f, -0.25f, \r\n\t\t\t0.25f,0.25f, -0.25f,\r\n\t\t\t// BOTTOM\r\n\t\t\t-0.25f, -0.25f, 0.25f, \r\n\t\t\t-0.25f, -0.25f, -0.25f, \r\n\t\t\t0.25f, -0.25f, 0.25f, \r\n\t\t\t0.25f,-0.25f, -0.25f, };\r\n\r\n\tFloatBuffer cubeBuff;\r\n\r\n\tfloat xrot = 0.0f;\r\n\tfloat yrot = 0.0f;\r\n\r\n\t/**\r\n\t * 将float数组转换存储在字节缓冲数组\r\n\t * \r\n\t * @param arr\r\n\t * @return\r\n\t */\r\n\tpublic FloatBuffer makeFloatBuffer(float[] arr) {\r\n\t\tByteBuffer bb = ByteBuffer.allocateDirect(arr.length * 4);// 分配缓冲空间，一个float占4个字节\r\n\t\tbb.order(ByteOrder.nativeOrder()); // 设置字节顺序，\r\n\t\t\t\t\t\t\t\t\t\t\t// 其中ByteOrder.nativeOrder()是获取本机字节顺序\r\n\t\tFloatBuffer fb = bb.asFloatBuffer(); // 转换为float型\r\n\t\tfb.put(arr); // 添加数据\r\n\t\tfb.position(0); // 设置数组的起始位置\r\n\t\treturn fb;\r\n\t}\r\n\r\n\tpublic CubeRenderer() {\r\n\t\tcubeBuff = makeFloatBuffer(box);// 转换float数组\r\n\t}\r\n\r\n\tprotected void init(GL10 gl) {\r\n\t\tgl.glClearColor(0.0f, 0.0f, 0.0f, 1.0f);// 设置清屏时背景的颜色，R，G，B，A\r\n\r\n\t\tgl.glEnable(GL10.GL_DEPTH_TEST); // 启用深度缓存\r\n\t\tgl.glEnable(GL10.GL_CULL_FACE); // 启用背面剪裁\r\n\t\tgl.glClearDepthf(1.0f); // 设置深度缓存值\r\n\t\tgl.glDepthFunc(GL10.GL_LEQUAL); // 设置深度缓存比较函数，GL_LEQUAL表示新的像素的深度缓存值小于等于当前像素的深度缓存值（通过gl.glClearDepthf(1.0f)设置）时通过深度测试\r\n\t\tgl.glShadeModel(GL10.GL_SMOOTH);// 设置阴影模式GL_SMOOTH\r\n\t}\r\n\r\n\t@Override\r\n\tpublic void onSurfaceCreated(GL10 gl, EGLConfig config) {\r\n\t\tinit(gl);\r\n\t}\r\n\r\n\t@Override\r\n\tpublic void onSurfaceChanged(GL10 gl, int w, int h) {\r\n\t\tgl.glViewport(0, 0, w, h); // 设置视窗\r\n\t\tgl.glMatrixMode(GL10.GL_PROJECTION); // 设置投影矩阵\r\n\t\tgl.glLoadIdentity(); // 设置矩阵为单位矩阵，相当于重置矩阵\r\n\t\tGLU.gluPerspective(gl, 45.0f, ((float) w) / h, 0.1f, 10f);// 设置透视范围\r\n\t}\r\n\r\n\t@Override\r\n\tpublic void onDrawFrame(GL10 gl) {\r\n\t\tgl.glClear(GL10.GL_COLOR_BUFFER_BIT | GL10.GL_DEPTH_BUFFER_BIT);// 清除屏幕和深度缓存\r\n\r\n\t\tgl.glMatrixMode(GL10.GL_MODELVIEW); // 切换至模型观察矩阵\r\n\t\tgl.glLoadIdentity();// 重置当前的模型观察矩阵\r\n\t\tGLU.gluLookAt(gl, 0, 0, 3, 0, 0, 0, 0, 1, 0);// 设置视点和模型中心位置\r\n\r\n\t\tgl.glVertexPointer(3, GL10.GL_FLOAT, 0, cubeBuff);// 设置顶点数据\r\n\t\tgl.glEnableClientState(GL10.GL_VERTEX_ARRAY);\r\n\r\n\t\tgl.glRotatef(xrot, 1, 0, 0); // 绕着(0,0,0)与(1,0,0)即x轴旋转\r\n\t\tgl.glRotatef(yrot, 0, 1, 0);\r\n\r\n\t\tgl.glColor4f(1.0f, 0, 0, 1.0f); // 设置颜色，红色\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 0, 4); // 绘制正方型FRONT面\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 4, 4);\r\n\r\n\t\tgl.glColor4f(0, 1.0f, 0, 1.0f);\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 8, 4);\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 12, 4);\r\n\r\n\t\tgl.glColor4f(0, 0, 1.0f, 1.0f);\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 16, 4);\r\n\t\tgl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 20, 4);\r\n\r\n\t\txrot += 1.0f;\r\n\t\tyrot += 0.5f;\r\n\t}\r\n}  \r\n\r\n2、主页显示 \r\n\r\n    package com.hust.dj3dstudy;\r\n\r\n    import android.app.Activity;\r\n    import android.opengl.GLSurfaceView;\r\n    import android.os.Bundle;\r\n    import android.view.Window;\r\n\r\n    public class MainActivity extends Activity {\r\n\r\n\tCubeRenderer mCubeRenderer; // 我们自定义的立方体Renderer\r\n\r\n\t@Override\r\n\tprotected void onCreate(Bundle savedInstanceState) {\r\n\t\tsuper.onCreate(savedInstanceState);\r\n\t\trequestWindowFeature(Window.FEATURE_NO_TITLE); // 去掉标题\r\n\t\tGLSurfaceView GLView = new GLSurfaceView(this); // 创建一个GLSurfaceView\r\n\t\tmCubeRenderer = new CubeRenderer();\r\n\t\tGLView.setRenderer(mCubeRenderer);\r\n\t\tsetContentView(GLView);\r\n\t}\r\n    }\r\n\r\n# UPDATE4:Hand Tracking 实现    \r\n    这周我们主要进行了Hand Tracking这个项目环境的搭建和相关算法的实现，现将部分核心代码公布如下  \r\n核心代码：\r\n\r\n\r\n\t/**\r\n\t * 初始化照相机视图\r\n\t */\r\n\tprivate void initOpenCVCamera() {\r\n\t\tmOpenCvCameraView = (CameraBridgeViewBase) findViewById(R.id.handtracking_activity_java_surface_view);\r\n\t\tmOpenCvCameraView.setVisibility(SurfaceView.VISIBLE);\r\n\t\tmOpenCvCameraView.setCvCameraViewListener(this);\r\n\t\tmOpenCvCameraView.setOnTouchListener(HandTrackingActivity.this);\r\n\t\tmOpenCvCameraView.setFocusable(false);\r\n\t}\r\n\r\n\t//相机开始预览执行\r\n\tpublic void onCameraViewStarted(int width, int height) {\r\n\t\tLog.e(TAG, \"-----------Widht: \" + width + \" Height: \" + height);\r\n\t\tHeight = height;\r\n\t\tWidth = width;\r\n\t\tmRgba = new Mat(height, width, CvType.CV_8UC3);\r\n\t\tmHsv = new Mat(); // (height, width, CvType.CV_8UC3);\r\n\t\tthreshold = new Mat(); // (height, width, CvType.CV_8UC3);\r\n\t\tkernel = Mat.zeros(KERNEL_SIZE, KERNEL_SIZE, CvType.CV_8UC1);\r\n\t\tCONTOUR_COLOR = new Scalar(255, 0, 0);\r\n\t\tmHierarchy = new Mat();\r\n\t\tsquares = getSquares(new Point(mRgba.width() / 2, mRgba.height() / 2),\r\n\t\t\t\t(int) (Width * 20) / 1280);\r\n\t\tmax_range = new int[squares.length][3];\r\n\t\tmin_range = new int[squares.length][3];\r\n\t\tfor (int i = 0; i < squares.length; i++) {\r\n\t\t\tfor (int j = 0; j < 3; j++) {\r\n\t\t\t\tmin_range[i][j] = 256;\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\t//相机结束预览执行\r\n\tpublic void onCameraViewStopped() {\r\n\t}\r\n\r\n\t//把预览的frame转换为OpenCV里面的Mat数据格式\r\n\tpublic Mat onCameraFrame(CvCameraViewFrame inputFrame) {\r\n\t\tmRgba = inputFrame.rgba();\r\n\t\tif (!haveRange) {\r\n\t\t\tfor (int i = 0; i < squares.length; i += 2) {\r\n\t\t\t\tCore.rectangle(mRgba, squares[i], squares[i + 1], new Scalar(\r\n\t\t\t\t\t\t255, 0, 0), 5);\r\n\t\t\t}\r\n\t\t\tCore.putText(mRgba, \"Position your hand on the squares and tap\",\r\n\t\t\t\t\tnew Point(mRgba.cols() * 0.25, mRgba.rows() * 0.9),\r\n\t\t\t\t\tCore.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 0, 0), 2);\r\n\t\t\tmOutput = mRgba;\r\n\t\t} else {\r\n\t\t\tif (Width / 3 > 320)\r\n\t\t\t\tImgproc.resize(mRgba, mRgba, new Size(Width / 3, Height / 3));\r\n\t\t\t// mRgba.convertTo(mRgba, -1, alpha, beta);\r\n\t\t\tImgproc.cvtColor(mRgba, mHsv, Imgproc.COLOR_RGB2HSV);\r\n\t\t\tmOutput = null;\r\n\t\t\tfor (int i = 0; i < squares.length; i++) {\r\n\t\t\t\tCore.inRange(mHsv, new Scalar(min_range[i][0], min_range[i][1],\r\n\t\t\t\t\t\tmin_range[i][2]), new Scalar(max_range[i][0],\r\n\t\t\t\t\t\tmax_range[i][1], max_range[i][2]), threshold);\r\n\t\t\t\tImgproc.GaussianBlur(threshold, threshold, new Size(11, 11), 0,\r\n\t\t\t\t\t\t0);\r\n\t\t\t\tif (i == 0)\r\n\t\t\t\t\tmOutput = threshold.clone();\r\n\t\t\t\telse\r\n\t\t\t\t\tCore.add(mOutput, threshold, mOutput);\r\n\t\t\t}\r\n\t\t\t/*\r\n\t\t\t * blur：均值滤波\r\n\t\t\t * GaussianBlur：高斯滤波\r\n\t\t\t * medianBlur：中值滤波\r\n\t\t\t * bilateralFilter：双边滤波\r\n\t\t\t * */\r\n\t\t\tImgproc.medianBlur(mOutput, mOutput, 11);//中值滤波\r\n\t\t\tImgproc.dilate(mOutput, mOutput, kernel);\r\n\t\t\tImgproc.erode(mOutput, mOutput, kernel);\r\n\r\n\t\t\tList<MatOfPoint> contours = new ArrayList<MatOfPoint>();\r\n\r\n\t\t\tImgproc.findContours(mOutput, contours, mHierarchy,\r\n\t\t\t\t\tImgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);\r\n\t\t\t// Find max contour area\r\n\t\t\tdouble maxArea = 0;\r\n\t\t\tIterator<MatOfPoint> each = contours.iterator();\r\n\t\t\tint i = 0, i_max = 0;\r\n\t\t\twhile (each.hasNext()) {\r\n\t\t\t\tMatOfPoint wrapper = each.next();\r\n\t\t\t\tdouble area = Imgproc.contourArea(wrapper);\r\n\t\t\t\tif (area > maxArea) {\r\n\t\t\t\t\tmaxArea = area;\r\n\t\t\t\t\ti_max = i;\r\n\t\t\t\t}\r\n\t\t\t\ti++;\r\n\t\t\t}\r\n\t\t\tImgproc.drawContours(mRgba, contours, i_max, CONTOUR_COLOR);\r\n\r\n\t\t\tif (Width / 3 > 320)\r\n\t\t\t\tImgproc.resize(mRgba, mRgba, new Size(Width, Height));\r\n\t\t}\r\n\t\treturn mRgba;\r\n\t}\r\n\r\n\t//触摸点击事件，切换HandTracking和非HandTracking的状态切换。\r\n\t//并且在屏幕中央绘制10个红框\r\n\t@Override\r\n\tpublic boolean onTouch(View v, MotionEvent event) {\r\n\t\tif (haveRange) {\r\n\t\t\thaveRange = false;\r\n\t\t\treturn false;\r\n\t\t}\r\n\t\thaveRange = true;\r\n\t\t// mRgba.convertTo(mRgba, -1, alpha, beta);\r\n\t\tImgproc.cvtColor(mRgba, mHsv, Imgproc.COLOR_RGB2HSV);\r\n\t\tList<Mat> channels = new ArrayList<Mat>();\r\n\t\tCore.split(mHsv, channels);\r\n\r\n\t\tfor (int c = 0; c < 3; c++) {\r\n\t\t\tMat ch = channels.get(c);\r\n\t\t\tfor (int s = 0; s < squares.length; s += 2) {\r\n\t\t\t\tMat subMat = ch.submat((int) squares[s].y,\r\n\t\t\t\t\t\t(int) squares[s + 1].y, (int) squares[s].x,\r\n\t\t\t\t\t\t(int) squares[s + 1].x);\r\n\t\t\t\tMinMaxLocResult result = Core.minMaxLoc(subMat);\r\n\t\t\t\tmin_range[s][c] = (int) result.minVal;\r\n\t\t\t\tmax_range[s][c] = (int) result.maxVal;\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\treturn false;\r\n\t}\r\n                            \r\n# UPDATE5：本次项目的最后一更  \r\n这周我们进行了项目最终的调试，并在Android设备上进行了最终的测试。    \r\n最终的Demo视频文件较大，可以点击下边链接下载：   \r\nhttp://pan.baidu.com/s/1bXTAoQ  \r\n这里是测试相关截图：  \r\n![](https://github.com/philniu/philniu.github.io/blob/master/update5images/Demo_20160620142318.JPG)\r\n![](https://github.com/philniu/philniu.github.io/blob/master/update5images/Demo_20160620142354.JPG)    \r\n源码，和最终的.apk文件可以点击下边链接下载：  \r\nhttps://github.com/philniu/philniu.github.io/tree/master/Hand%20Tracking    \r\nCaution! HandTracking.apk和OpenCV_2.4.11_Manager_2.20_armv7a-neon.apk都要安装，使用时，先点击openCV，再点击HandTracking！  \r\n不足：   \r\n在Demo中也可以看到，要想获得好的Track效果，background一定要均匀且相对稳定，反差越大越好，鲁棒性差。  \r\n\r\n\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}